{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bc24811-73ed-4208-bde5-1dff5c791d26",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required modules\n",
    "import tskit\n",
    "import cyvcf2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36564c-6759-466c-b9ad-9a6f0d073d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample DF\n",
    "sample_df = pd.read_table(snakemake.config[\"samples\"], sep=\"\\t\")\n",
    "sample_df = sample_df[[\"Sample\", \"Habitat\"]]\n",
    "\n",
    "# Load order of BAM files and merge with sample DF\n",
    "bams = pd.read_table(snakemake.input[\"bams\"][0], names=[\"bam\"])\n",
    "bams[\"Sample\"] = bams[\"bam\"].str.extract(\"(s_\\\\d+_\\\\d+)\")\n",
    "bams = bams.merge(sample_df, on = \"Sample\", how = \"left\")[[\"Sample\", \"Habitat\"]]\n",
    "\n",
    "# Get indices or urban, rural, and suburban samples in BAM list\n",
    "# This corresponds to their indices in the VCFs used to build the ARGs\n",
    "urban_sample_indices = bams.index[bams[\"Habitat\"] == \"Urban\"].tolist()\n",
    "rural_sample_indices = bams.index[bams[\"Habitat\"] == \"Rural\"].tolist()\n",
    "suburban_sample_indices = bams.index[bams[\"Habitat\"] == \"Suburban\"].tolist()\n",
    "\n",
    "# Map habitat names to integers and then get population of each index\n",
    "habitat_pop_map = {\"Urban\": 0, \"Suburban\": 1, \"Rural\": 2}\n",
    "sample_indices = {k: {} for k in range(len(bams) * 2)}\n",
    "for i, r in bams.iterrows():\n",
    "    sample_indices[i*2][\"population\"] = habitat_pop_map[r[\"Habitat\"]]\n",
    "    sample_indices[(i*2) + 1][\"population\"] = habitat_pop_map[r[\"Habitat\"]]\n",
    "\n",
    "# Get haplotype indices for each sample\n",
    "urban_hap_indices = [k for k,v in sample_indices.items() if v[\"population\"] == 0]\n",
    "rural_hap_indices = [k for k,v in sample_indices.items() if v[\"population\"] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3804a0-4334-46fc-b78d-ae38cadb4a4a",
   "metadata": {},
   "source": [
    "## Extract site-based Fst estimates\n",
    "\n",
    "### Estimates from `SINGER` ARGs\n",
    "\n",
    "- Nei's site-based estimate of Fst from Bhatia (2013) and branch-based estimator from Slatkin (1991).\n",
    "    - See [this GitHub issue](https://github.com/tskit-dev/tskit/issues/858)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff010c7-82c3-4984-ac5e-a2c342bb1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "results = {\"pos_index\": [], \n",
    "           \"pos\": [], \n",
    "           \"arg_branch_fst\": [], \n",
    "           \"arg_site_fst\": [], \n",
    "           \"gt_hudson_num\": [],\n",
    "           \"gt_hudson_denom\": [],\n",
    "           \"gt_hudson_fst\": [], \n",
    "           \"gt_nei_num\": [], \n",
    "           \"gt_nei_denom\": [], \n",
    "           \"gt_nei_fst\": [], \n",
    "           \"sfs_hudson_num\": [],\n",
    "           \"sfs_hudson_denom\": [],\n",
    "           \"sfs_hudson_fst\": [],\n",
    "}\n",
    "\n",
    "# Parse inputs and parameters\n",
    "region = f\"region{snakemake.wildcards['n']}\"\n",
    "n_samples = int(snakemake.params[\"n_samples\"])\n",
    "arg_path = snakemake.params['arg_path']\n",
    "\n",
    "# Iterate over posterior ARG samples and get branch and site Fst at every site\n",
    "# Stored as lists with n_samples elements, where each element is a 1D array of size ts.num_sites\n",
    "branch_fsts = []\n",
    "site_fsts = []\n",
    "for s in range(n_samples):\n",
    "    ts = tskit.load(f\"{arg_path}/trees/{region}/{region}_{s}.trees\")\n",
    "    branch_fst = ts.Fst([urban_hap_indices, rural_hap_indices], mode=\"branch\", windows=\"sites\", span_normalise=False)\n",
    "    branch_fsts.append(branch_fst)\n",
    "    site_fst = ts.Fst([urban_hap_indices, rural_hap_indices], mode=\"site\", windows=\"sites\", span_normalise=False)\n",
    "    site_fsts.append(branch_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe59b94-b16c-4982-954e-551f3d6ee961",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.num_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be3e9f-29b8-4cfe-9d8d-9f917b32a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean Fst of each site across samples\n",
    "mean_branch_fsts = np.nanmean(branch_fsts, axis = 0)\n",
    "mean_site_fsts = np.nanmean(site_fsts, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1025f-ef52-4f4f-9319-75b7cd19cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ARG-based Fst estimates to results dictionary\n",
    "for i in range(ts.num_sites):\n",
    "    results[\"pos_index\"].append(i)\n",
    "    results[\"arg_branch_fst\"].append(mean_branch_fsts[i])\n",
    "    results[\"arg_site_fst\"].append(mean_site_fsts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ca574-da2f-46ea-896e-26d79d77e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results[\"arg_site_fst\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a3499-aa0e-4507-8954-6a542c55d9e2",
   "metadata": {},
   "source": [
    "### Estimates from genotypes\n",
    "\n",
    "- Will estimate both Nei's and Hudson's Fst from Bhatia (2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5bd81c-b245-4b36-812a-51a9a35ea471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load urban and rural VCFs\n",
    "urban_vcf = cyvcf2.VCF(snakemake.input[\"vcf\"][0], samples = bams.Sample[bams[\"Habitat\"] == \"Urban\"].tolist())\n",
    "rural_vcf = cyvcf2.VCF(snakemake.input[\"vcf\"][0], samples = bams.Sample[bams[\"Habitat\"] == \"Rural\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b1230-99e1-405c-aac7-344f966080a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries with SNP positions as keys and alternative allele frequencies as values\n",
    "# Do this for both urban and rural populations\n",
    "urban_af_dict = {f\"{snp.CHROM}:{snp.POS}\": [snp.aaf] for snp in urban_vcf}\n",
    "rural_af_dict = {f\"{snp.CHROM}:{snp.POS}\": [snp.aaf] for snp in rural_vcf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988706e7-e8c3-4ef0-995e-1efc6f96ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urban_af_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e988c4-07cb-499e-8795-984e0cf9943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_urban = len(urban_sample_indices)\n",
    "n_rural = len(rural_sample_indices)\n",
    "\n",
    "for snp, af in urban_af_dict.items():\n",
    "    u_af = af[0]  # Allele frequency in urban population\n",
    "    r_af = rural_af_dict[snp][0]  # Allele frequency at same site in rural population\n",
    "\n",
    "    # Hudson's Fst\n",
    "    a = (u_af - r_af) ** 2\n",
    "    b = (u_af * (1 - u_af)) / (n_urban - 1)\n",
    "    c = (r_af * (1 - r_af)) / (n_rural - 1)\n",
    "    d = (u_af * (1 - r_af))\n",
    "    e = (r_af * (1 - u_af))\n",
    "    gt_hudson_numerator = a - b - c\n",
    "    gt_hudson_denominator = d + e  # Will be 0 if u_af = r_af = 0\n",
    "    if gt_hudson_denominator == 0:\n",
    "        gt_hudson_fst = np.nan  # To prevent division by zero. Set to NaN instead of 0\n",
    "    else:\n",
    "        gt_hudson_fst = gt_hudson_numerator / gt_hudson_denominator\n",
    "    \n",
    "    # Nei's Fst\n",
    "    avg_af = (u_af + r_af) / 2\n",
    "    gt_nei_numerator = (u_af - r_af) ** 2\n",
    "    gt_nei_denominator = avg_af * (1 - avg_af)\n",
    "    if gt_nei_denominator == 0:\n",
    "        gt_nei_fst = np.nan\n",
    "    else:\n",
    "        gt_nei_fst = gt_nei_numerator / gt_nei_denominator\n",
    "        \n",
    "    results[\"pos\"].append(snp)\n",
    "    results[\"gt_hudson_num\"].append(gt_hudson_numerator)\n",
    "    results[\"gt_hudson_denom\"].append(gt_hudson_denominator)\n",
    "    results[\"gt_hudson_fst\"].append(gt_hudson_fst)\n",
    "    results[\"gt_nei_num\"].append(gt_nei_numerator)\n",
    "    results[\"gt_nei_denom\"].append(gt_nei_denominator)\n",
    "    results[\"gt_nei_fst\"].append(gt_nei_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05fdb6-d7b9-4974-b9e8-e6c63066a5d6",
   "metadata": {},
   "source": [
    "## SFS-based Fst estimates\n",
    "\n",
    "- Estimates Hudson's Fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989fd2e-90b4-4271-af95-efffec5bc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ANGSD SFS readable Hudson Fst data as pandas dictionary\n",
    "chrom = results[\"pos\"][0].split(\":\")[0]\n",
    "hudson_sfs_fst_path = [p for p in snakemake.input[\"sfs_fst\"] if chrom in p][0]\n",
    "hudson_sfs_fst_df = pd.read_table(hudson_sfs_fst_path, sep='\\t', usecols=[1,2,3], names = [\"pos\", \"num\", \"denom\"]).set_index('pos')\n",
    "hudson_sfs_fst_dict = hudson_sfs_fst_df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109aed5e-7f1d-4029-86a7-19704c7f2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hudson Fst numerators, denominators, and Fst for SFS positions overlapping Genotypes/ARGs\n",
    "for pos in results[\"pos\"]:\n",
    "    position = int(pos.split(\":\")[1])\n",
    "    if position in hudson_sfs_fst_dict.keys():\n",
    "        sfs_hudson_numerator = hudson_sfs_fst_dict[position][\"num\"]\n",
    "        sfs_hudson_denominator = hudson_sfs_fst_dict[position][\"denom\"]\n",
    "        if sfs_hudson_denominator == 0:\n",
    "            sfs_hudson_fst = np.nan\n",
    "        else:\n",
    "            sfs_hudson_fst = sfs_hudson_numerator / sfs_hudson_denominator\n",
    "    else:\n",
    "        sfs_hudson_numerator = np.nan\n",
    "        sfs_hudson_denominator = np.nan\n",
    "        sfs_hudson_fst = np.nan\n",
    "    \n",
    "    results[\"sfs_hudson_num\"].append(sfs_hudson_numerator)\n",
    "    results[\"sfs_hudson_denom\"].append(sfs_hudson_denominator)\n",
    "    results[\"sfs_hudson_fst\"].append(sfs_hudson_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5900de3-3956-4a99-83fc-2d69d8f82d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(results)\n",
    "df_out[\"regionID\"] = snakemake.wildcards[\"n\"]\n",
    "df_out.to_csv(snakemake.output[0], index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
